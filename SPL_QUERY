Stats SUM & AVG FILLNULL -----------


index="_internal" 
| table bytes, source, sourcetype
| stats sum(bytes) as sum_bytes, avg(bytes) as avg_bytes by sourcetype
| fillnull value="NULL" sum_bytes
| fillnull  avg_bytes
| sort  sourcetype


LIST & VALUES -----

index="_internal" 
| stats list(source) as source by sourcetype

index="_internal" 
| stats values(source) as source by sourcetype


EVAL - Round, Calculation & Concetination


index="_internal" 
| eval kb = bytes/1024
| eval kb_round = round(kb,3)
| eval kb_concat = kb_round." KB"
| table kb, kb_round,kb_concat, bytes

Optimized COde ---

index="_internal" 
```| eval kb = bytes/1024
| eval kb_round = round(kb,3)
| eval kb_concat = kb_round." KB"```
| eval kb_output = round(bytes/1024,2)." KB"
| table kb_output bytes

IF-ELSE Condition -----

index=vk_snow 
| dedup current_ticket_state
| table current_ticket_state
| eval ticket_state = if(current_ticket_state="Closed" OR current_ticket_state="Resolved", "Completed", "Incomplete")

CASE ----

index=vk_snow 
| dedup severity 
| table severity 
| eval sev = case( severity=1,"Critical", severity=2, "High", severity=3, "normal", 1=1, "Low")
| sort severity

Timechart ----

index=vk_snow 
|timechart span=1y count by current_ticket_state

Date & Time Function ----

index=vk_snow 
| table _time, current_ticket_state, time_submitted
| eval time_submitted_epoc = strptime(time_submitted,"%d-%m-%y %H:%M")
| eval _time = time_submitted_epoc
| timechart span=1y count by current_ticket_state

index="vk_snow" sourcetype="csv" 
| table time_submitted 
| eval time_submitted_epoc = strptime(time_submitted, "%d-%m-%y %H:%M") 
| eval time_submitted_format = strftime(time_submitted_epoc, "%d-%b-%Y %A")

GeoStats ----

index="vk_snow" sourcetype="csv" source="vendors.csv" | geostats latfield=VendorLatitude longfield=VendorLongitude count by VendorCountry

Join ----

Inner ---

index=vk_snow source=Sample_tickets.csv 
| table ticket_number, severity, current_ticket_state, time_taken 
| join type=inner ticket_number
    [ search index=vk_snow source=Sample_lookup.csv ticket_number=INC0000205* 
    | table ticket_number, time_taken]

index=vk_snow source=Sample_tickets.csv 
| table ticket_number, severity, current_ticket_state, time_taken 
| join type=left ticket_number
    [ search index=vk_snow source=Sample_lookup.csv ticket_number=INC0000205* 
    | table ticket_number, time_taken]

Overwrite Function ----

index=vk_snow source=Sample_tickets.csv 
| eval time_taken="NULL" 
| table ticket_number, severity, current_ticket_state, time_taken 
| join type=inner ticket_number overwrite=true
    [ search index=vk_snow source=Sample_lookup.csv ticket_number=INC0000205* 
    | table ticket_number, time_taken]


index=vk_snow source=Sample_tickets.csv 
| eval time_taken="NULL" 
| table ticket_number, severity, current_ticket_state, time_taken 
| join type=left ticket_number overwrite=true
    [ search index=vk_snow source=Sample_lookup.csv ticket_number=INC0000205* 
    | table ticket_number, time_taken]


append ---

index=vk_snow source=Sample_tickets.csv 
| stats count by current_ticket_state 
| append
    [ search index=vk_snow source=Sample_lookup.csv 
    | stats count as total by time_taken]

appendcols ---

index=vk_snow source=Sample_tickets.csv 
| stats count by current_ticket_state 
| appendcols 
    [ search index=vk_snow source=Sample_lookup.csv 
    | stats count as total by time_taken]

appendpipe ---

index="vk_snow" sourcetype="csv" source="Sample_tickets.csv" 
| stats count by severity, current_ticket_state 
| appendpipe 
    [| stats sum(count) as count by severity 
    | eval current_ticket_state="Sum by Severity Wise"] 
| sort severity

Rex ---

URL - https://www.debuggex.com/cheatsheet/regex/pcre
https://regex101.com/


source="data.txt"  index="vk_snow" sourcetype="vk_txt" 
| rex field=_raw "From:\s+<(?P<from_id>.*)>\s+To" 
| table from_id


| makeresults 
| eval text = "vk;search;saved_search" 
| rex field=text "(?P<name>\w+);(?P<app_name>\w+);(?P<savedsearchname>\w+)" 
| fields - _time

AddColtotal & Addtotal ----

index=vk_snow source="Sample_tickets.csv" 
| chart count by current_ticket_state, severity 
| addcoltotals label=total labelfield=current_ticket_state 
| addtotals fieldname=Sum

==============================================================================================================================

Assignment No - 2 -------------

Input ----

| makeresults 
| eval credit_card_number="1234-5678-9020-1415"

Output ---

credit_card_number
1234
5678
9020
1415

============================================================================================================================================

Solution Assignment - 2

| makeresults 
| eval credit_card_number="1234-5678-9020-1415" 
| rex field=credit_card_number "(?P<digit>\d{4})" max_match=0


Spath ----

index="vk_snow" sourcetype="vk_xml" source="test_xml.txt" 
| spath path=purchases.book.author output=author


index="vk_snow" sourcetype="vk_xml" source="test_xml.txt" 
| spath path=purchases.book.title output=title 
| spath path=purchases.book.author output=author 
| spath path=purchases.book.title{@yearPublished} output=yearPublished

index="vk_snow" sourcetype="vk_xml" source="raw_nyc_phil_mod.json" 
| spath path=programs{}.concerts{}.Venue output=venue


index="vk_snow" sourcetype="vk_xml" source="mixed_json_unstructured.json" 
| rex field=_raw "xyz-\s+(?P<extracted_json>.*)" 
| spath input=extracted_json


Search & WHere Commands -----

index=vk_snow source=Sample_tickets.csv 
| stats count by severity 
| eval threshold=15 
| where count>threshold


index=vk_snow source=Sample_tickets.csv 
| stats count by severity 
|search count>20

===============================================================================================================================

Assignment - 2

Write the Cron Expression ----> Mon to fri, 10AM to 7PM, Every Hour in the month of Jan, March & April

Assignment -3 

API vs Webhook??

Assignment 4 ---

Get the use case to justify the interdependecy between Time range and Schedule in aLERT that might led to false alert.

=================================================================================================================================

Lookup ----


|inputlookup vk_sample_lookup.csv



index=vk_snow source=Sample_tickets.csv 
| table ticket_number, severity, current_ticket_state 
| lookup vk_sample_lookup.csv ticket_number OUTPUT time_taken as time_consumed


KVStore ----

| makeresults
| eval id=1, name="Vivek"
| fields - _time
| outputlookup vk_kvstore

| inputlookup vk_kvstore
| eval key = _key

=============================================================================================================================

Assignment - 5 ----

Integrate the multiselect.js file with the XML Dashboard.

============================================================================================================================

Assignment - 6 ---

Calling the savedsearch on the xml dashboard.

===================================================================================================================================

HEC Token ----

curl -k https://localhost:8088/services/collector -H "Authorization:Splunk 2944d671-b9af-4f3d-ba67-92f6653d03f0" -d "{\"sourcetype\":\"trial\", \"event\":\"hello world\"}"


C:\Windows\System32>curl -k "https://localhost:8088/services/collector?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"sourcetype\":\"trail123\", \"event\":\"ack events\"}"
{"text":"Success","code":0,"ackId":0}
C:\Windows\System32>curl -k "https://localhost:8088/services/collector?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"sourcetype\":\"trail123\", \"event\":\"ack events1\"}"
{"text":"Success","code":0,"ackId":1}
C:\Windows\System32>curl -k "https://localhost:8088/services/collector?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"sourcetype\":\"trail123\", \"event\":\"ack events2\"}"
{"text":"Success","code":0,"ackId":2}
C:\Windows\System32>curl -k "https://localhost:8088/services/collector?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"sourcetype\":\"trail123\", \"event\":\"ack events3\"}"
{"text":"Success","code":0,"ackId":3}

Verify ---

C:\Windows\System32>curl -k "https://localhost:8088/services/collector/ack?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"acks\":[0]}"
{"acks":{"0":true}}
C:\Windows\System32>curl -k "https://localhost:8088/services/collector/ack?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"acks\":[12]}"
{"acks":{"12":false}}
C:\Windows\System32>curl -k "https://localhost:8088/services/collector/ack?channel=ae4d57f8-866f-4276-8dfa-d197c02ce308" -H "Authorization:Splunk 7e42c38b-b8c2-4c37-b4bf-67c503c99ce5" -d "{\"acks\":[2]}"

================================================================================================================================================================================


Diag ---- C:\Program Files\Splunk\bin>splunk diag

=================================================================================================================================================================================

Splunk UF ----

 Linux --- wget -O splunkforwarder-9.4.0-6b4ebe426ca6-linux-amd64.tgz "https://download.splunk.com/products/universalforwarder/releases/9.4.0/linux/splunkforwarder-9.4.0-6b4ebe426ca6-linux-amd64.tgz"

Windows --- wget -O splunkforwarder-9.4.0-6b4ebe426ca6-windows-x64.msi "https://download.splunk.com/products/universalforwarder/releases/9.4.0/windows/splunkforwarder-9.4.0-6b4ebe426ca6-windows-x64.msi"
